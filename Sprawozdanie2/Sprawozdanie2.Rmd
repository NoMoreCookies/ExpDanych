---
title: "Sprawozdanie 2"
author: "Kacper Szmigielski, 282255 i Mateusz Wizner, 277508"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
  pdf_document:
    toc: true
    fig_caption: true
    fig_width: 5
    fig_height: 4
    toc_depth: 3
    number_sections: true
    keep_tex: true
header-includes:
- \usepackage[OT4]{polski}
- \usepackage[utf8]{inputenc}
- \usepackage{graphicx}
- \usepackage{float}
- \usepackage{xcolor}
subtitle: Eksploracja danych
fontsize: 12pt
---

```{r setup, include=FALSE}
#USTAWIENIA DO PROJEKTU 
### echo = FALSE (Nie wypisuje kodu przy egzekucji programu)
### message = FALSE (Nie wyświetla jakiś powiadomień)
### warning = Flase (Nie wyświetla błędów jak się pojawią)
#---------------------------------------------------------

knitr::opts_chunk$set(echo = FALSE )
knitr::opts_chunk$set(message = FALSE, warning = FALSE )
knitr::opts_chunk$set(gif.pos = "H", out.extra = "", fig.align = "center")

#---------------------------------------------------------
```

```{r DATA_IMPORT}
#IMPORT DANYCH
#---------------------------------------------------------

data <- read.csv("uaScoresDataFrame.csv") 
#head(data)


#---------------------------------------------------------
```

```{r Import_bibliotek}
#POTRZEBNE BIBLIOTEKI
#---------------------------------------------------------
library(knitr)
library(dplyr)
library(kableExtra)
library(patchwork)
library(ggplot2)
library(arules)
library(e1071)
library(tidyr)
library(visdat)
library(xtable)
library(DataExplorer)
library(moments)
#---------------------------------------------------------
```
# ZADANIE 1 (Dyskretyzacja(przedziałowanie) cech ciągłych)
##  a) Dane: iris (R-pakiet datasets).

**3** Pierwsze wiersze z pakietu iris
```{r Dane_iris_przykład}
#DANE
#---------------------------------------------------------
data <- iris
#---------------------------------------------------------
kable(head(data,3))
```
Zbiór danych zawiera wyniki pomiarów uzyskanych dla **trzech gatunków irysów** (tj. setosa, versicolor i virginica) i został **udostępniony przez Ronalda Fishera w roku 1936.**

– **Pomiary** dotyczą **długości oraz szerokości** dwóch różnych części kwiatu– działki **kielicha (ang. sepal) oraz płatka (ang. petal).**

##  b) Wybór cech

Cechy, inaczej właściwie możemy to rozstrzygać jako kolumny, które charakteryzują się **największym zróżnicowaniem** w stosunku do rodzaju gatunku


```{r zad1b}
#TWORZENIE WYKRESÓW 1
#---------------------------------------------------------
p1 <- ggplot(data,aes(x = Sepal.Length,col = Species))+
  geom_histogram()
p2 <- ggplot(data,aes(x = Sepal.Width,col = Species))+
  geom_histogram()
p3 <- ggplot(data,aes(x = Petal.Length,col = Species))+
  geom_histogram()
p4 <- ggplot(data,aes(x = Petal.Width,col = Species))+
  geom_histogram()
#---------------------------------------------------------

#RYSOWANIE WYKRESÓW
#---------------------------------------------------------
(p1 + p2) / (p3 + p4) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom",)
#---------------------------------------------------------

```

Po przeanalizowaniu histogramów, widać ,że warto zwrócić uwagę na takie cechy jak **Petal.Length i Petal.Width**, ponieważ

widać dobrze zaznaczone przedziały w których występuje większość kwiatków danego gatunku.

Dalej warto jest też spojrzeć na to jak nasze *obserwawcje* teoretycznie rozkładają się w przestrzeni 2D, aby to zrobić
dodajemy jedną dodatkową kolumnę y, wypełnioną losowymi liczbami od 0 do 1 (rozkłąd jednostajny)

```{r zad1b1}
#DODATKOWY WIERSZ DO WIZUALIZACJI
#-----/----------------------------------------------------
data$y <- runif(nrow(data))
#---------------------------------------------------------

#TWORZENIE WYKRESÓW
#---------------------------------------------------------
p1 <- ggplot(data,aes(x = Sepal.Length,y=y,col = Species))+
  geom_point()
p2 <- ggplot(data,aes(x = Sepal.Width,y=y ,col = Species))+
  geom_point()
p3 <- ggplot(data,aes(x = Petal.Length,y=y ,col= Species))+
  geom_point()
p4 <- ggplot(data,aes(x = Petal.Width,y=y ,col=Species))+
  geom_point()
#---------------------------------------------------------


#RYSOWANIE WYKRESÓW
#---------------------------------------------------------
(p1 + p2) / (p3 + p4) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom",)
#---------------------------------------------------------

```

Wykresy typu scatter-plot potwierdzają ,że **Petal.Length i Petal.Width** są bardzo dobry wyborem cech, które mogłyby być wyznacznikami gatunków roślin.

Musimy jednak wybrać wartości najlepsze i najgorsze, aby to zrobić przeanalizujemy jeszcze boxploty.

```{r zad1b2}

#TWORZENIE WYKRESÓW
#---------------------------------------------------------
p1 <- ggplot(data,aes(x = Sepal.Length,y=Species,col = Species))+
  geom_boxplot()
p2 <- ggplot(data,aes(x = Sepal.Width,y=Species ,col = Species))+
  geom_boxplot()
p3 <- ggplot(data,aes(x = Petal.Length,y=Species ,col= Species))+
  geom_boxplot()
p4 <- ggplot(data,aes(x = Petal.Width,y=Species ,col=Species))+
  geom_boxplot()
#---------------------------------------------------------

#RYSOWANIE WYKRESÓW
#---------------------------------------------------------
(p1 + p2) / (p3 + p4) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom",)
#---------------------------------------------------------

```
Na ich podstawaie możemy uznać, że Petal.Width może stanowić najlepszy wyznacznik gatunku roślin
Najgorszym natomiast jest Sepal.Width, tutaj duża część gatunków dzieli te same wartości tej cechy.

##  c) Porównanie nienadzorowanych metod dyskretyzacji

```{r Przygotowanie_danych}
#PRZYGOTOWANIE DANUYCH TRENINGOWYCH
#---------------------------------------------------------
trainingData1 <- data$Petal.Width
trainingData2 <- data$Sepal.Length
#---------------------------------------------------------
```

```{r drawing_hist_method}

#DEFINIOWANIE METODY
#---------------------------------------------------------
hist_plot <- function(trainingData,method){
  
  results <- discretize(trainingData, breaks = 3, method = method)
  breaks.equal.frq <- attributes(results)$"discretized:breaks"
  
  return (ggplot(data,aes(x = trainingData1,col = Species,main="Metoda: equal frequency discretization"))+
  geom_histogram()+
    geom_vline(xintercept = breaks.equal.frq, col = "red", lwd=0.5))
}
#---------------------------------------------------------

```

```{r drawing scatter_metohod}
#DEFINIOWANIE METODY
#---------------------------------------------------------
scatter_plot <- function(trainingData,method){
  
  results <- discretize(trainingData, breaks = 3, method = method)
  breaks.equal.frq<- attributes(results)$"discretized:breaks"
  
  return (ggplot(data,aes(x = trainingData,y=y ,col=Species))+
  geom_point()+
geom_vline(xintercept = breaks.equal.frq, col = "red", lwd=0.5))
}
#---------------------------------------------------------

```

### Równe częstości

#### Dla najlepszej
```{r frequences_najl}

#FREQUENCE_METHOD
#---------------------------------------------------------
hist_plot(trainingData1,"Frequency")
scatter_plot(trainingData1,"Frequency")
#---------------------------------------------------------
```

```{r tabela_kondygnacji_1_najl}
results <- discretize(trainingData1, breaks = 3, method = "Frequency")
plot(iris$Species~results, col=1:3)
```

```{r tabela_zgodności_1_najl}
compareMatchedClasses(data$Species, results)$diag
```

#### Dla najgorszej

```{r frequences_najg}

#FREQUENCE_METHOD
#---------------------------------------------------------
hist_plot(trainingData2,"Frequency")
scatter_plot(trainingData2,"Frequency")
#---------------------------------------------------------
```

```{r tabela_kondygnacji_1_najg}
results <- discretize(trainingData2, breaks = 3, method = "Frequency")
plot(iris$Species~results, col=1:3)
```

```{r tabela_zgodności_1_najg}
compareMatchedClasses(data$Species, results)$diag
```

### Równe szerokości

#### Dla najlepszej

```{r width_najl}


#WIDTH_METHOD
#---------------------------------------------------------
hist_plot(trainingData1,"Interval")
scatter_plot(trainingData1,"Interval")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_2_najl}
results <- discretize(trainingData1, breaks = 3, method = "Interval")
plot(iris$Species~results, col=1:3)

```

```{r tabela_zgodności_2_najl}

compareMatchedClasses(data$Species, results)$diag
```

#### Dla najgorszej

```{r width_najg}


#WIDTH_METHOD
#---------------------------------------------------------
hist_plot(trainingData2,"Interval")
scatter_plot(trainingData2,"Interval")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_2_najg}
results <- discretize(trainingData2, breaks = 3, method = "Interval")
plot(iris$Species~results, col=1:3)

```

```{r tabela_zgodności_2_najg}

compareMatchedClasses(data$Species, results)$diag
```

### K-means

#### Dla najlepszej

```{r kMeans_najl}
#WIDTH_METHOD
#---------------------------------------------------------
hist_plot(trainingData1,"Cluster")
scatter_plot(trainingData1,"Cluster")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_3_najl}
results <- discretize(trainingData1, breaks = 3, method = "Cluster")
plot(iris$Species~results, col=1:3)

```

```{r tabela_zgodności_3_najl}

compareMatchedClasses(data$Species, results)$diag
```

#### Dla najgorszej

```{r kMeans_najg}
#WIDTH_METHOD
#---------------------------------------------------------
hist_plot(trainingData2,"Cluster")
scatter_plot(trainingData2,"Cluster")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_3_najg}
results <- discretize(trainingData2, breaks = 3, method = "Cluster")
plot(iris$Species~results, col=1:3)

```

```{r tabela_zgodności_3_najg}

compareMatchedClasses(data$Species, results)$diag[1]
```

### Dyskretyzacja z przedziałami zadanymi przez urzytkownika

#### Dla najlepszej

```{r givenRanges_najl}
#GIVEN_RANGES
#---------------------------------------------------------
x.disc.user <- discretize(trainingData1, method = "fixed", 
      breaks = c(-Inf, 0.5, 1.8, Inf), labels = c("small","medium", "large"))

hist(trainingData1, breaks = 10, main = "Metoda: fixed (user provided breaks)")
breaks.user <- c(-Inf, 0.5, 1.8, Inf)
abline(v = breaks.user, col = "red", lwd=2)


plot(trainingData1, data$y, col=iris$Species, main = "Metoda: fixed (user provided breaks)")
abline(v = breaks.user, col = "red", lwd=3)
legend(x = "topright", legend=levels(iris$Species), col=1:3, pch=21, bg = "azure")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_4_najl}
results <- discretize(trainingData1, breaks = 3, method = "Cluster")
plot(iris$Species~results, col=1:3)

```

```{r tabela_zgodności_4_najl}

compareMatchedClasses(data$Species, results)$diag
```

#### Dla najgorszej

```{r givenRanges_najg}
#GIVEN_RANGES
#---------------------------------------------------------
x.disc.user <- discretize(trainingData2, method = "fixed", 
      breaks = c(-Inf, 5, 6, Inf), labels = c("small","medium", "large"))

hist(trainingData2, breaks = 10, main = "Metoda: fixed (user provided breaks)")
breaks.user <- c(-Inf, 5, 6, Inf)
abline(v = breaks.user, col = "red", lwd=2)


plot(trainingData2, data$y, col=iris$Species, main = "Metoda: fixed (user provided breaks)")
abline(v = breaks.user, col = "red", lwd=3)
legend(x = "topright", legend=levels(iris$Species), col=1:3, pch=21, bg = "azure")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_4_najg}
results <- discretize(trainingData2, breaks = 3, method = "Cluster")
plot(iris$Species~results, col=1:3)

```

```{r tabela_zgodności_4_najg}
compareMatchedClasses(data$Species, results)$diag
```

# ZADANIE 2 (Analizaskładowych głównych (Principal Component Analysis (PCA)))

##  a) Przygotowanie danych

```{r import_przygotowanie_danych}
# =====================================================================
# a) Import i przygotowanie danych
# =====================================================================

# --- Wczytanie danych ---
data <- read.csv("uaScoresDataFrame.csv")
```


```{r podstawowe_info}
kable(t(introduce(data)), 
      row.names = TRUE, col.names = "",
      caption = "Podstawowe informacje nt. danych `uaScoresDataFrame`")

```

Typy danych w zbiorze

```{r typy_danych, fig.width=14, fig.height=2}
# Typy zmiennych
#kable(data.frame(Type = sapply(data, class)), caption = "Typy danych w zbiorze")
vis_dat(data) +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank())

# --- Wybór cech ilościowych ---
data_numeric <- data[sapply(data, is.numeric) & names(data) != "X"]
```

```{r wykresy_jakosciowe, fig.width=14, fig.height=4}
ggplot(data, aes(x = UA_Continent, fill = UA_Continent)) + 
  geom_bar() +
  ggtitle("Wykres słupkowy dla UA_Continent") +
  scale_fill_brewer(palette = "Set3") +
  scale_y_continuous(breaks = seq(0, max(table(data$UA_Continent)), by = 10))

ggplot(data, aes(x = UA_Country, fill = ..count..)) +
  geom_bar() +
  ggtitle("Wykres słupkowy dla UA_Country alfabetycznie") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8)) +
  scale_y_continuous(breaks = seq(0, max(table(data$UA_Country)), by = 1)) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(x = "Kraj", y = "Liczba", fill = "Liczba")

data_sorted <- data %>%
  count(UA_Country) %>%
  arrange(n)

ggplot(data_sorted, aes(x = reorder(UA_Country, n), y = n, fill = n)) +
  geom_bar(stat = "identity") +
  ggtitle("Wykres słupkowy dla UA_Country rosnąco") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8)) +
  scale_y_continuous(breaks = seq(0, max(data_sorted$n), by = 1)) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(x = "Kraj", y = "Liczba", fill = "Liczba")
```

```{r histogramy_ilosciowe1, fig.height=10, fig.width=10}
plot_histogram_with_density <- function(data_numeric, nrow = 4, ncol = 5, 
                                       title = "Histogramy z estymatorami gęstości", 
                                       adjust = 0.5) {
  data_long <- data_numeric %>%
    gather(key = "Variable", value = "Value")
  
  ggplot(data_long, aes(x = Value)) +
    geom_histogram(aes(y = after_stat(density)), 
                  bins = 30, 
                  fill = "lightblue", 
                  color = "darkblue", 
                  alpha = 0.7) +
    geom_density(adjust = adjust, 
                color = "red", 
                linewidth = 1) +
    geom_boxplot(aes(y = -0.02), 
                width = 0.1, 
                fill = "orange", 
                alpha = 0.7,
                outlier.color = "red",
                outlier.size = 1.5) +
    facet_wrap(~ Variable, scales = "free", nrow = nrow, ncol = ncol) +
    labs(title = title) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16),
      strip.text = element_text(size = 10, face = "bold"),
      axis.title.x = element_blank(),
      axis.text.x = element_text(angle = 45, hjust = 1, size = 8)
    )
}

plot_histogram_with_density(
  data_numeric,
  nrow = 4,
  ncol = 5,
  title = "Histogramy z estymatorami gęstości i boxplotami dla zmiennych ilościowych",
  adjust = 0.3
)

```

```{r qq_z_kurtoza, fig.height=10, fig.width=10}
plot_qq_kurtosis <- function(data_numeric, nrow = 4, ncol = 5) {
  data_long <- data_numeric %>%
    gather(key = "Variable", value = "Value")
  
  get_kurtosis <- function(x) {
    kurtosis_val <- round(kurtosis(x, na.rm = TRUE), 2)
    return(kurtosis_val)
  }
  
  kurtosis_stats <- data_long %>%
    group_by(Variable) %>%
    summarise(
      kurtosis = get_kurtosis(Value),
      .groups = "drop"
    ) %>%
    mutate(
      kurtosis_type = case_when(
        kurtosis < 3 ~ "platykurtyczny",
        kurtosis > 3 ~ "leptokurtyczny",
        TRUE ~ "mezokurtyczny"
      ),
      label = paste0("Kurtoza: ", kurtosis, " (", kurtosis_type, ")")
    )
  data_with_kurtosis <- left_join(data_long, kurtosis_stats, by = "Variable")
  
  ggplot(data_with_kurtosis, aes(sample = Value)) +
    stat_qq(color = "steelblue", size = 1, alpha = 0.7) +
    stat_qq_line(color = "darkblue", linewidth = 0.8) +
    geom_text(
      aes(x = -2, y = Inf, label = label),
      hjust = 0, vjust = 1,
      size = 2.5, color = "black",
      check_overlap = TRUE
    ) +
    labs(
      title = "Wykresy Q-Q dla zmiennych ilościowych",
    ) +
    facet_wrap(~ Variable, scales = "free", nrow = nrow, ncol = ncol) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5, size = 10),
      strip.text = element_text(size = 10, face = "bold"),
      strip.background = element_rect(fill = "lightyellow", color = "grey"),
      panel.background = element_rect(fill = "white", color = NA),
      panel.grid.major = element_line(color = "gray90"),
      panel.grid.minor = element_line(color = "gray95"),
      axis.text = element_text(size = 5)
    )
}

plot_qq_kurtosis(data_numeric, nrow = 4, ncol = 5)
```

```{r wykresy_korelacji, fig.height=10, fig.width=10}
plot_correlation(na.omit(data), type="continuous",
                 title="Macierz korelacji dla zmiennych ciągłych")
```


```{r znaczace_korelacje}
find_significant_correlations <- function(data, alpha = 0.05) {
  numeric_data <- data %>% select_if(is.numeric)
  var_names <- names(numeric_data)
  results <- data.frame(Variable1 = character(), Variable2 = character(), Correlation = numeric(), P_Value = numeric(), stringsAsFactors = FALSE)

  for (i in 1:(length(var_names) - 1)) {
    for (j in (i + 1):length(var_names)) {
      var1 <- var_names[i]
      var2 <- var_names[j]
      complete_data <- numeric_data[complete.cases(numeric_data[, c(var1, var2)]), c(var1, var2)]
      
      if (nrow(complete_data) > 2) {
        cor_test <- cor.test(complete_data[[var1]], complete_data[[var2]])
        
        if (cor_test$p.value < alpha) {
          results <- rbind(results, data.frame(Variable1 = var1, Variable2 = var2, Correlation = cor_test$estimate, P_Value = cor_test$p.value))
        }
      }
    }
  }
  
  results <- results %>% mutate(Abs_Correlation = abs(Correlation)) %>% arrange(desc(Abs_Correlation)) %>% select(-Abs_Correlation)
  return(results)
}

visualize_top_correlations <- function(data, top_n = 10) {
  significant_correlations <- find_significant_correlations(data)

  top_correlations <- significant_correlations %>% head(min(top_n, nrow(significant_correlations)))

  plot_data <- top_correlations %>%
    mutate(Pair = paste(Variable1, "&", Variable2), Pair = factor(Pair, levels = rev(Pair)), P_Value = format.pval(P_Value, digits = 3))

  ggplot(plot_data, aes(x = Correlation, y = Pair, fill = Correlation)) +
    geom_col() +
    scale_fill_gradient2(low = "firebrick", mid = "white", high = "steelblue", midpoint = 0, limits = c(-1, 1)) +
    labs(title = paste("Najsilniejsze istotne korelacje (top", min(top_n, nrow(significant_correlations)), ")"), x = "Współczynnik korelacji", y = NULL) +
    theme_minimal() +
    theme(legend.position = "none", plot.title = element_text(hjust = 0.5, size = 14, face = "bold"), axis.text.y = element_text(size = 10), panel.grid.major.y = element_line(color = "gray90"), panel.grid.minor = element_blank()) +
    geom_text(aes(label = sprintf("r = %.3f (p = %s)", Correlation, P_Value)), hjust = ifelse(plot_data$Correlation > 0, -0.1, 1.1), size = 3.5) +
    scale_x_continuous(limits = c(-1, 1))
}

visualize_top_correlations(na.omit(data), top_n = 10)
```


```{r tabelka_pierwszych_wierszy}
# Pierwsze wiersze danych
index <- 0:(nrow(head(data)) - 1)

kable(head(data)[, 1:6],
      format = "pandoc",
      booktabs = TRUE,
      digits = 3,
      table.attr = "style='width:100%; font-size:5px;'")

kable(cbind(X = index, head(data)[, 7:11]),
      format = "pandoc",
      booktabs = TRUE,
      digits = 3)

kable(cbind(X = index, head(data)[, 12:16]),
      format = "pandoc",
      booktabs = TRUE,
      digits = 3)

kable(cbind(X = index, head(data)[, 17:ncol(data)]),
      format = "pandoc",
      booktabs = TRUE,
      digits = 3)
```


```{r tabela_wariancji}
# --- Analiza wariancji cech ---
variances <- apply(data_numeric, 2, function(x) var(x, na.rm = TRUE))
kable(data.frame(Wariancja = variances), 
      digits = 3,
      col.names = c("Wariancja"), 
      format = "markdown")

# --- Wniosek ---
# Wariancje cech różnią się znacznie – konieczna jest standaryzacja przed analizą PCA.
# =====================================================================
```

```{r wykresy_rozkładów_standaryzacja_boxplot}
# =====================================================================
# a) Wykresy rozkładów przed i po standaryzacji
# =====================================================================

# --- Funkcja pomocnicza do rysowania wykresów ---
plot_boxplot <- function(df, title, fill_color, line_color) {
  df_melted <- pivot_longer(as.data.frame(df), cols = everything(), names_to = "Cechy", values_to = "Wartość")
  ggplot(df_melted, aes(x = Cechy, y = Wartość)) +
    geom_boxplot(fill = fill_color, color = line_color, alpha = 0.7) +
    labs(title = title, x = "Cechy", y = "Wartość") +
    theme_minimal(base_size = 10) +
    theme(axis.text.x = element_text(angle = 60, hjust = 1),
          axis.title.x = element_text(size = 14),
          axis.title.y = element_text(size = 14))
}

# --- Wykres cech przed standaryzacją ---
plot_boxplot(data_numeric, "Rozkład cech ilościowych przed standaryzacją", "skyblue", "darkblue")

# --- Standaryzacja danych ---
data_numeric_scaled <- scale(data_numeric)

# --- Wykres cech po standaryzacji ---
plot_boxplot(data_numeric_scaled, "Rozkład cech ilościowych po standaryzacji", "lightgreen", "darkgreen")
# =====================================================================

```

##  b) Wyznaczenie składowych głównych

```{r PCA_składowe_wariancja_tabela}
# =====================================================================
# b) Wyznaczenie składowych głównych (PCA)
# =====================================================================

# --- PCA ---
pca <- prcomp(data_numeric_scaled)

# --- Tabela podsumowująca wyniki PCA ---
tabela_pca <- data.frame(
  Składowa = paste0("PC", 1:17),
  Odchylenie_standardowe = c(2.251, 1.606, 1.443, 1.140, 1.095, 0.980, 0.831, 0.815, 0.764, 0.651, 
                             0.569, 0.539, 0.524, 0.434, 0.393, 0.352, 0.313),
  Procent_wariancji = c(29.8, 15.16, 12.25, 7.65, 7.05, 5.65, 4.06, 3.90, 3.43, 2.50,
                        1.90, 1.71, 1.62, 1.11, 0.91, 0.73, 0.58),
  Kumulatywna_wariancja = c(29.8, 44.96, 57.21, 64.86, 71.90, 77.55, 81.62, 85.52, 88.95, 91.45,
                            93.35, 95.06, 96.68, 97.79, 98.69, 99.42, 100)
)

kable(tabela_pca, "pandoc", caption = "Podsumowanie analizy PCA") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = FALSE,
                position = "center") %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(2:4, width = "4cm") %>%
  row_spec(0, bold = TRUE, background = "#f2f2f2")

# --- Wniosek ---
# Składowa PC1 wyjaśnia około 30% zmienności, PC2 około 15%. Rozkład zmienności jest stosunkowo rozproszony.
# =====================================================================

```


##  c) Zmienność odpowiadająca poszczególnym składowym

```{r rozklad_wartosci_wykres_boxplot}
# =====================================================================
# c) Rozkład wartości składowych głównych
# =====================================================================

# --- Przygotowanie danych ---
pca_data <- as.data.frame(pca$x)

pca_melted <- pivot_longer(pca_data, cols = everything(), names_to = "Składowa", values_to = "Wartość")
pca_melted$Składowa <- factor(pca_melted$Składowa, levels = paste0("PC", seq_len(ncol(pca_data))))

# --- Wykres ---
ggplot(pca_melted, aes(x = Składowa, y = Wartość)) +
  geom_boxplot(fill = "plum", color = "purple", alpha = 0.7) +
  labs(title = "Rozkład wartości składowych głównych", x = "Składowa główna", y = "Wartość") +
  theme_minimal(base_size = 10) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14))
# =====================================================================

```

```{r ladunki}
# =====================================================================
# Wektory ładunków (Loadings)
# =====================================================================

# --- Wektory ładunków dla pierwszych trzech składowych ---
loadings <- pca$rotation

kable(as.data.frame(loadings[, 1:3]), caption = "Wektory ładunków dla PC1, PC2 i PC3") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE,
                position = "center") %>%
  row_spec(0, bold = TRUE, background = "#f2f2f2")

# =====================================================================

```

```{r Zmiennosc_skladowych_w_PCA}
# =====================================================================
# Zmienność odpowiadająca poszczególnym składowym
# =====================================================================

# --- Obliczenie procentu wyjaśnionej wariancji ---
variance_explained <- (pca$sdev^2) / sum(pca$sdev^2)
cumulative_variance <- cumsum(variance_explained)

# --- Przygotowanie danych do wykresu ---
df_variance <- data.frame(PC = seq_along(variance_explained), Variance = variance_explained)

# --- Wykres procentu wyjaśnionej wariancji ---
ggplot(df_variance, aes(x = PC, y = Variance)) +
  geom_bar(stat = "identity", fill = "cornflowerblue", alpha = 0.7) +
  geom_line(aes(group = 1), color = "darkblue", linetype = "dashed", size = 1) +
  geom_point(color = "red", size = 3) +
  labs(title = "Procent wyjaśnionej wariancji przez składowe główne",
       x = "Numer składowej głównej", y = "Procent wariancji") +
  theme_minimal(base_size = 10) +
  scale_x_continuous(breaks = seq_along(df_variance$PC)) +
  scale_y_continuous(labels = scales::percent_format())

# --- Wykres skumulowanej wariancji ---
ggplot(data.frame(PC = seq_along(cumulative_variance), CumulativeVariance = cumulative_variance)) +
  geom_point(aes(x = PC, y = CumulativeVariance), color = "blue", size = 3) +
  geom_line(aes(x = PC, y = CumulativeVariance), color = "blue", linetype = "dashed") +
  geom_hline(yintercept = c(0.80, 0.90), linetype = "dashed", color = c("red", "green")) +
  annotate("text", x = 15, y = c(0.82, 0.92), label = c("80% wariancji", "90% wariancji"),
           color = c("red", "green")) +
  labs(title = "Kumulatywna wariancja wyjaśniona przez składowe główne",
       x = "Numer składowej głównej", y = "Kumulatywna proporcja wariancji") +
  theme_minimal(base_size = 10) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

# --- Ile składowych potrzeba do wyjaśnienia 80% i 90% wariancji? ---
num_components_80 <- min(which(cumulative_variance >= 0.80))
num_components_90 <- min(which(cumulative_variance >= 0.90))
# =====================================================================
```

Liczba składowych głównych wyjaśniających **80%** wariancji: **`r num_components_80`**  
Liczba składowych głównych wyjaśniających **90%** wariancji: **`r num_components_90`**


##  d) Wizualizacja danych wielowymiarowych

```{r}

#_________________________________________________________________________________________________

```

##  e) Korelacja zmiennych



##  f) Końcowe wnioski




# ZADANIE 3 (Skalowaniewielowymiarowe (Multidimensional Scaling (MDS)))
##  a) Dane: titanic_train (R-pakiet titanic)
##  b) Przygotowanie danych
##  c) Redukcja wymiaru na bazie MDS
##  d) Wizualizacja danych
