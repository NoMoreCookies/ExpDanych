---
title: "Sprawozdanie 2"
author: "Kacper Szmigielski, 282255 i Mateusz Wizner, 277508"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    fig_caption: true
    fig_width: 5
    fig_height: 4
    toc_depth: 3
    number_sections: true
    keep_tex: true
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
header-includes:
- \usepackage[OT4]{polski}
- \usepackage[utf8]{inputenc}
- \usepackage{graphicx}
- \usepackage{float}
- \usepackage{xcolor}
subtitle: Eksploracja danych
fontsize: 12pt
---

```{r setup, include=FALSE}
#USTAWIENIA DO PROJEKTU 
### echo = FALSE (Nie wypisuje kodu przy egzekucji programu)
### message = FALSE (Nie wyświetla jakiś powiadomień)
### warning = Flase (Nie wyświetla błędów jak się pojawią)
#---------------------------------------------------------

knitr::opts_chunk$set(echo = FALSE )
knitr::opts_chunk$set(message = FALSE, warning = FALSE )
knitr::opts_chunk$set(gif.pos = "H", out.extra = "", fig.align = "center")

#---------------------------------------------------------
```

```{r DATA_IMPORT}
#IMPORT DANYCH
#---------------------------------------------------------
data <- read.csv("uaScoresDataFrame.csv") 
#head(data)
#---------------------------------------------------------
```

```{r Import_bibliotek}
#POTRZEBNE BIBLIOTEKI
#---------------------------------------------------------
library(knitr)
library(dplyr)
library(kableExtra)
library(patchwork)
library(ggplot2)
library(arules)
library(e1071)
library(tidyr)
library(xtable)
library(glue)
#---------------------------------------------------------
```

# ZADANIE 1 (Dyskretyzacja(przedziałowanie) cech ciągłych)

## a) Dane: iris (R-pakiet datasets).

**3** Pierwsze wiersze z pakietu iris

```{r Dane_iris_przykład}
#DANE
#---------------------------------------------------------
data <- iris
#---------------------------------------------------------
```

Zbiór danych zawiera wyniki pomiarów uzyskanych dla **trzech gatunków irysów** (tj. setosa, versicolor i virginica) i został **udostępniony przez Ronalda Fishera w roku 1936.**

– **Pomiary** dotyczą **długości oraz szerokości** dwóch różnych części kwiatu– działki **kielicha (ang. sepal) oraz płatka (ang. petal).**

## b) Wybór cech

Szukamy cech, których róznice są najbardziej spójne z różnicami pomiędzy gatunkami.

```{r zad1b}
#TWORZENIE WYKRESÓW 1
#---------------------------------------------------------
p1 <- ggplot(data,aes(x = Sepal.Length,col = Species))+
  geom_histogram()
p2 <- ggplot(data,aes(x = Sepal.Width,col = Species))+
  geom_histogram()
p3 <- ggplot(data,aes(x = Petal.Length,col = Species))+
  geom_histogram()
p4 <- ggplot(data,aes(x = Petal.Width,col = Species))+
  geom_histogram()
#---------------------------------------------------------

#RYSOWANIE WYKRESÓW (ONE TROCHĘ ZAŚMIECAJĄ I NIE SĄ POTRZEBNE)

#---------------------------------------------------------
#(p1 + p2) / (p3 + p4) +
#  plot_layout(guides = "collect") &
#  theme(legend.position = "bottom",)
#---------------------------------------------------------

```

```{r zad1b1}
#DODATKOWY WIERSZ DO WIZUALIZACJI
#-----/----------------------------------------------------
data$y <- runif(nrow(data))
#---------------------------------------------------------

#TWORZENIE WYKRESÓW
#---------------------------------------------------------
p1 <- ggplot(data,aes(x = Sepal.Length,y=y,col = Species))+
  geom_point()
p2 <- ggplot(data,aes(x = Sepal.Width,y=y ,col = Species))+
  geom_point()
p3 <- ggplot(data,aes(x = Petal.Length,y=y ,col= Species))+
  geom_point()
p4 <- ggplot(data,aes(x = Petal.Width,y=y ,col=Species))+
  geom_point()
#---------------------------------------------------------


#RYSOWANIE WYKRESÓW
#---------------------------------------------------------
(p1 + p2) / (p3 + p4) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom",)
#---------------------------------------------------------

```

Po przeanalizowaniu scatter-plotów, widać ,że podczas szukania cechy o najlepszej zdolności dyskryminacyjnej warto zwrócić uwagę na **Petal.Length i Petal.Width**, natomiast jeżeli poszukujemy kolumny o najgorszej zdolności dyskryminacyjnej to wybór rozsztrzygamy spośród **Sepal.Length i Sepal.Width**

Musimy jednak wybrać **wartości najlepsze i najgorsze** do dyksryminacji, aby to zrobić przeanalizujemy **box-ploty**.

```{r zad1b2}

#TWORZENIE WYKRESÓW
#---------------------------------------------------------
p1 <- ggplot(data,aes(x = Sepal.Length,y=Species,col = Species))+
  geom_boxplot()
p2 <- ggplot(data,aes(x = Sepal.Width,y=Species ,col = Species))+
  geom_boxplot()
p3 <- ggplot(data,aes(x = Petal.Length,y=Species ,col= Species))+
  geom_boxplot()
p4 <- ggplot(data,aes(x = Petal.Width,y=Species ,col=Species))+
  geom_boxplot()
#---------------------------------------------------------

#RYSOWANIE WYKRESÓW
#---------------------------------------------------------
(p1 + p2) / (p3 + p4) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom",)
#---------------------------------------------------------

```

Na ich podstawie możemy uznać, że **Petal.Width może stanowić najlepszy wyznacznik gatunku** roślin Najgorszym natomiast jest **Sepal.Width**. Ponieważ dla **Petal.Width** gatunki w najmniejszym stopniu się pokrywają ze względu na tą cechę , a w **Sepal.Width** w największym.

## c) Porównanie nienadzorowanych metod dyskretyzacji

```{r Przygotowanie_danych}
#PRZYGOTOWANIE DANUYCH TRENINGOWYCH
#---------------------------------------------------------
trainingData1 <- data$Petal.Width
trainingData2 <- data$Sepal.Length
#---------------------------------------------------------
```

```{r drawing_hist_method}

#DEFINIOWANIE METODY
#---------------------------------------------------------
hist_plot <- function(trainingData,method){
  
  results <- discretize(trainingData, breaks = 3, method = method)
  breaks.equal.frq <- attributes(results)$"discretized:breaks"
  
  return (ggplot(data,aes(x = trainingData1,col = Species,main=glue("Metoda: {method}")))+
  geom_histogram()+
    geom_vline(xintercept = breaks.equal.frq, col = "red", lwd=0.5))
}
#---------------------------------------------------------

```

```{r drawing scatter_metohod}
#DEFINIOWANIE METODY
#---------------------------------------------------------
scatter_plot <- function(trainingData,method){
  
  results <- discretize(trainingData, breaks = 3, method = method)
  breaks.equal.frq<- attributes(results)$"discretized:breaks"
  
  return (ggplot(data,aes(x = trainingData,y=y ,col=Species))+
  geom_point()+
geom_vline(xintercept = breaks.equal.frq, col = "red", lwd=0.5))
}
#---------------------------------------------------------

```

```{r przygotowanie_wyników}

R1 <- c()
R2 <- c()

```

### Metoda : Równe częstości(Frequency)

#### Dla najlepszej cechy : Petal.Length (Frequency)

```{r frequences_najl}

#FREQUENCE_METHOD
#---------------------------------------------------------
#hist_plot(trainingData1,"Frequency")(Tego nie, niepotrzebnie zajmuje miejsce)
scatter_plot(trainingData1,"Frequency")
#---------------------------------------------------------
```

```{r tabela_kondygnacji_1_najl}
results <- discretize(trainingData1, breaks = 3, method = "Frequency")
plot(iris$Species~results, col=1:3)
```

W przypadku tej metody **zgodność** uzyskanego grupowania z realnymi wartościami **wynosi** :

```{r tab_zgodn}
R <- compareMatchedClasses(data$Species, results)$diag[1][1]
R1 <- c(R1,R)
```

#### Dla najgorszej cechy : Sepal.Length (Frequency)

```{r frequences_najg}

#FREQUENCE_METHOD
#---------------------------------------------------------
#hist_plot(trainingData2,"Frequency")(Zajjmuje miejsce niepotrzebnie)
scatter_plot(trainingData2,"Frequency")
#---------------------------------------------------------
```

```{r tabela_kondygnacji_1_najg}
results <- discretize(trainingData2, breaks = 3, method = "Frequency")
plot(iris$Species~results, col=1:3)
```

Zgodność dla nagjroszej cechy wynosi jedynie ok **72%**, co mówi o znacznym spadku wiarygodności (**o ok 23 %**)

```{r tabela_zgodności_1_najg}
R <- compareMatchedClasses(data$Species, results)$diag[1][1]
R2 <- c(R2,R)
```

### Metoda : Równe szerokości (Interval)

#### Dla najlepszej cechy : Petal.Width (Interval)

```{r width_najl}


#WIDTH_METHOD
#---------------------------------------------------------
#hist_plot(trainingData1,"Interval")
scatter_plot(trainingData1,"Interval")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_2_najl}
results <- discretize(trainingData1, breaks = 3, method = "Interval")
plot(iris$Species~results, col=1:3)

```

Dla tej metody również mamy **zgodność na poziomie** :

```{r tabela_zgodności_2_najl}
R <- compareMatchedClasses(data$Species, results)$diag[1][1]
R1 <- c(R1,R)
```

Widać lekki wzrost zgodności w porównaniu do poprzedniej metody (**o ok 1%**)

#### Dla najgorszej cechy ; Sepal.Length (Interval)

```{r width_najg}


#WIDTH_METHOD
#---------------------------------------------------------
#hist_plot(trainingData2,"Interval")Niepotrzebnie zajmuje miejsce
scatter_plot(trainingData2,"Interval")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_2_najg}
results <- discretize(trainingData2, breaks = 3, method = "Interval")
plot(iris$Species~results, col=1:3)

```

Metoda ta, dla najgorszzej cechy dyksryminuje ze zgodnością :

```{r tabela_zgodności_2_najg}

R <- compareMatchedClasses(data$Species, results)$diag[1][1]
R2 <- c(R2,R)
```

Czyli w porównaniu do metody Frequency mamy **spadek** aż **o ok 16%**

### Metoda : k najbliższych sąsiadów (K-means)

#### Dla najlepszej cechy : Petal.Width (K-means)

```{r kMeans_najl}
#WIDTH_METHOD
#---------------------------------------------------------
#hist_plot(trainingData1,"Cluster")
scatter_plot(trainingData1,"Cluster")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_3_najl}
results <- discretize(trainingData1, breaks = 3, method = "Cluster")
plot(iris$Species~results, col=1:3)

```

Zgodność na poziomie :

```{r tabela_zgodności_3_najl}
R <- compareMatchedClasses(data$Species, results)$diag[1][1]
R1 <- c(R1,R)

```

Lepsza **o ok 3%** od ubiegłej metody

#### Dla najgorszej cechy : Sepal.Length (K-means)

```{r kMeans_najg}
#WIDTH_METHOD
#---------------------------------------------------------
#hist_plot(trainingData2,"Cluster")
scatter_plot(trainingData2,"Cluster")
#---------------------------------------------------------

```

```{r tabela_kondygnacji_3_najg}
results <- discretize(trainingData2, breaks = 3, method = "Cluster")
plot(iris$Species~results, col=1:3)

```

Dla najgorszej cechy mamy zgodność :

```{r tabela_zgodności_3_najg}

R <- compareMatchedClasses(data$Species, results)$diag[1][1]
R2 <- c(R2,R)

```

W tym przypadku jest ona **na poziome metody Frequency (gorsza o 1)**

### Dyskretyzacja z przedziałami zadanymi przez urzytkownika (fixed)

#### Dla najlepszej cechy : Petal.Width (fixed)

```{r givenRanges_najl}
#GIVEN_RANGES
#---------------------------------------------------------
x.disc.user <- discretize(trainingData1, method = "fixed", 
      breaks = c(-Inf, 0.5, 1.8, Inf), labels = c("small","medium", "large"))

breaks.user <- c(0,0.9,1.8,2.6)

ggplot(data,aes(x = trainingData1,y=data$y ,col=Species))+
  geom_point()+
geom_vline(xintercept = breaks.user, col = "red", lwd=0.5)
#---------------------------------------------------------

```

Na wykresie mamy zaznaczone też końce przedziałów, to jest potrzebne, co jest potrzebne podczas rysowania kolejnego wykresu

```{r tabela_kondygnacji_4_najl}
results <- cut(trainingData1, breaks = breaks.user, include.lowest = TRUE, right = FALSE)
plot(iris$Species~results, col=1:3)

```

Zgodność na poziome poprzednich dwóch metod, wynosi :

```{r tabela_zgodności_4_najl}

R <- compareMatchedClasses(data$Species, results)$diag[1][1]
R1 <- c(R1,R)
```

#### Dla najgorszej cechy : Sepal.Length (fixed)

```{r givenRanges_najg}
#GIVEN_RANGES
#---------------------------------------------------------
x.disc.user <- discretize(trainingData2, method = "fixed", 
      breaks = c(-Inf, 5, 6, Inf), labels = c("small","medium", "large"))

#hist(trainingData2, breaks = 10, main = "Metoda: fixed (user provided breaks)")
#breaks.user <- c(-Inf, 5, 6, Inf)
#abline(v = breaks.user, col = "red", lwd=2)
breaks.user <- c(4.2,5,6,8)

ggplot(data,aes(x = trainingData2 ,y=data$y ,col=Species))+
  geom_point()+
geom_vline(xintercept = breaks.user, col = "red", lwd=0.5)
#---------------------------------------------------------

```

```{r tabela_kondygnacji_4_najg}
results <- discretize(trainingData2, breaks = 3, method = "Cluster")
plot(iris$Species~results, col=1:3)

```

Dla cechy o najgorszej zdolności dyskryminacyjnej :

```{r tabela_zgodności_4_najg}
R <- compareMatchedClasses(data$Species, results)$diag[1][1]
R2 <- c(R2,R)
```

## Wnioski :

**Porównamy teraz** zgodności procentowe **wyników**, dla **poszczególnych algorytmów**

```{r RESULTS}

RESULTS <- data.frame(R1,R2)
RESULTS <- t(RESULTS)

colnames(RESULTS) <- c("frequency","interval","cluster","fixed")
rownames(RESULTS)<- c("Petal.Width","Sepal.Length")
kable(RESULTS)
```

Na podstawie tabeli, dokłądniej **Porównania przyporządkować dla cech najgorszych i najlepszych pod względem dyskryminacji**. Możemy wnioskować, że dla obecnych danych **najlepszym algorytmem** **jest frequency(częstość)** odznacza się najlepszym przyporządkowaniem zarówno dla Sepal.Length jak i Petal.Width

# ZADANIE 2 (Analizaskładowych głównych (Principal Component Analysis (PCA)))

## a) Przygotowanie danych

```{r import_przygotowanie_danych}
# =====================================================================
# a) Import i przygotowanie danych
# =====================================================================

# --- Wczytanie danych ---
data <- read.csv("uaScoresDataFrame.csv")

# Typy zmiennych
kable(data.frame(Type = sapply(data, class)), caption = "Typy danych w zbiorze")

# --- Wybór cech ilościowych ---
data_numeric <- data[sapply(data, is.numeric) & names(data) != "X"]
```

```{r tabelka_pierwszych_wierszy}
# Pierwsze wiersze danych
index <- 0:(nrow(head(data)) - 1)

kable(head(data)[, 1:6],
      format = "pandoc",
      booktabs = TRUE,
      digits = 3,
      table.attr = "style='width:100%; font-size:5px;'")

kable(cbind(X = index, head(data)[, 7:11]),
      format = "pandoc",
      booktabs = TRUE,
      digits = 3)

kable(cbind(X = index, head(data)[, 12:16]),
      format = "pandoc",
      booktabs = TRUE,
      digits = 3)

kable(cbind(X = index, head(data)[, 17:ncol(data)]),
      format = "pandoc",
      booktabs = TRUE,
      digits = 3)
```

```{r tabela_wariancji}
# --- Analiza wariancji cech ---
variances <- apply(data_numeric, 2, function(x) var(x, na.rm = TRUE))
kable(data.frame(Wariancja = variances), 
      digits = 3,
      col.names = c("Wariancja"), 
      format = "markdown")

# --- Wniosek ---
# Wariancje cech różnią się znacznie – konieczna jest standaryzacja przed analizą PCA.
# =====================================================================
```

```{r wykresy_rozkładów_standaryzacja_boxplot}
# =====================================================================
# a) Wykresy rozkładów przed i po standaryzacji
# =====================================================================

# --- Funkcja pomocnicza do rysowania wykresów ---
plot_boxplot <- function(df, title, fill_color, line_color) {
  df_melted <- pivot_longer(as.data.frame(df), cols = everything(), names_to = "Cechy", values_to = "Wartość")
  ggplot(df_melted, aes(x = Cechy, y = Wartość)) +
    geom_boxplot(fill = fill_color, color = line_color, alpha = 0.7) +
    labs(title = title, x = "Cechy", y = "Wartość") +
    theme_minimal(base_size = 10) +
    theme(axis.text.x = element_text(angle = 60, hjust = 1),
          axis.title.x = element_text(size = 14),
          axis.title.y = element_text(size = 14))
}

# --- Wykres cech przed standaryzacją ---
plot_boxplot(data_numeric, "Rozkład cech ilościowych przed standaryzacją", "skyblue", "darkblue")

# --- Standaryzacja danych ---
data_numeric_scaled <- scale(data_numeric)

# --- Wykres cech po standaryzacji ---
plot_boxplot(data_numeric_scaled, "Rozkład cech ilościowych po standaryzacji", "lightgreen", "darkgreen")
# =====================================================================

```

## b) Wyznaczenie składowych głównych

```{r PCA_składowe_wariancja_tabela}
# =====================================================================
# b) Wyznaczenie składowych głównych (PCA)
# =====================================================================

# --- PCA ---
pca <- prcomp(data_numeric_scaled)

# --- Tabela podsumowująca wyniki PCA ---
tabela_pca <- data.frame(
  Składowa = paste0("PC", 1:17),
  Odchylenie_standardowe = c(2.251, 1.606, 1.443, 1.140, 1.095, 0.980, 0.831, 0.815, 0.764, 0.651, 
                             0.569, 0.539, 0.524, 0.434, 0.393, 0.352, 0.313),
  Procent_wariancji = c(29.8, 15.16, 12.25, 7.65, 7.05, 5.65, 4.06, 3.90, 3.43, 2.50,
                        1.90, 1.71, 1.62, 1.11, 0.91, 0.73, 0.58),
  Kumulatywna_wariancja = c(29.8, 44.96, 57.21, 64.86, 71.90, 77.55, 81.62, 85.52, 88.95, 91.45,
                            93.35, 95.06, 96.68, 97.79, 98.69, 99.42, 100)
)

kable(tabela_pca, "pandoc", caption = "Podsumowanie analizy PCA") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = FALSE,
                position = "center") %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(2:4, width = "4cm") %>%
  row_spec(0, bold = TRUE, background = "#f2f2f2")

# --- Wniosek ---
# Składowa PC1 wyjaśnia około 30% zmienności, PC2 około 15%. Rozkład zmienności jest stosunkowo rozproszony.
# =====================================================================

```

## c) Zmienność odpowiadająca poszczególnym składowym

```{r rozklad_wartosci_wykres_boxplot}
# =====================================================================
# c) Rozkład wartości składowych głównych
# =====================================================================

# --- Przygotowanie danych ---
pca_data <- as.data.frame(pca$x)

pca_melted <- pivot_longer(pca_data, cols = everything(), names_to = "Składowa", values_to = "Wartość")
pca_melted$Składowa <- factor(pca_melted$Składowa, levels = paste0("PC", seq_len(ncol(pca_data))))

# --- Wykres ---
ggplot(pca_melted, aes(x = Składowa, y = Wartość)) +
  geom_boxplot(fill = "plum", color = "purple", alpha = 0.7) +
  labs(title = "Rozkład wartości składowych głównych", x = "Składowa główna", y = "Wartość") +
  theme_minimal(base_size = 10) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        axis.title.x = element_text(size = 14),
        axis.title.y = element_text(size = 14))
# =====================================================================

```

```{r ladunki}
# =====================================================================
# Wektory ładunków (Loadings)
# =====================================================================

# --- Wektory ładunków dla pierwszych trzech składowych ---
loadings <- pca$rotation

kable(as.data.frame(loadings[, 1:3]), caption = "Wektory ładunków dla PC1, PC2 i PC3") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE,
                position = "center") %>%
  row_spec(0, bold = TRUE, background = "#f2f2f2")

# =====================================================================

```

```{r Zmiennosc_skladowych_w_PCA}
# =====================================================================
# Zmienność odpowiadająca poszczególnym składowym
# =====================================================================

# --- Obliczenie procentu wyjaśnionej wariancji ---
variance_explained <- (pca$sdev^2) / sum(pca$sdev^2)
cumulative_variance <- cumsum(variance_explained)

# --- Przygotowanie danych do wykresu ---
df_variance <- data.frame(PC = seq_along(variance_explained), Variance = variance_explained)

# --- Wykres procentu wyjaśnionej wariancji ---
ggplot(df_variance, aes(x = PC, y = Variance)) +
  geom_bar(stat = "identity", fill = "cornflowerblue", alpha = 0.7) +
  geom_line(aes(group = 1), color = "darkblue", linetype = "dashed", size = 1) +
  geom_point(color = "red", size = 3) +
  labs(title = "Procent wyjaśnionej wariancji przez składowe główne",
       x = "Numer składowej głównej", y = "Procent wariancji") +
  theme_minimal(base_size = 10) +
  scale_x_continuous(breaks = seq_along(df_variance$PC)) +
  scale_y_continuous(labels = scales::percent_format())

# --- Wykres skumulowanej wariancji ---
ggplot(data.frame(PC = seq_along(cumulative_variance), CumulativeVariance = cumulative_variance)) +
  geom_point(aes(x = PC, y = CumulativeVariance), color = "blue", size = 3) +
  geom_line(aes(x = PC, y = CumulativeVariance), color = "blue", linetype = "dashed") +
  geom_hline(yintercept = c(0.80, 0.90), linetype = "dashed", color = c("red", "green")) +
  annotate("text", x = 15, y = c(0.82, 0.92), label = c("80% wariancji", "90% wariancji"),
           color = c("red", "green")) +
  labs(title = "Kumulatywna wariancja wyjaśniona przez składowe główne",
       x = "Numer składowej głównej", y = "Kumulatywna proporcja wariancji") +
  theme_minimal(base_size = 10) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

# --- Ile składowych potrzeba do wyjaśnienia 80% i 90% wariancji? ---
num_components_80 <- min(which(cumulative_variance >= 0.80))
num_components_90 <- min(which(cumulative_variance >= 0.90))
# =====================================================================
```

Liczba składowych głównych wyjaśniających **80%** wariancji: **`r num_components_80`**\
Liczba składowych głównych wyjaśniających **90%** wariancji: **`r num_components_90`**

## d) Wizualizacja danych wielowymiarowych

## e) Korelacja zmiennych

## f) Końcowe wnioski

# ZADANIE 3 (Skalowaniewielowymiarowe (Multidimensional Scaling (MDS)))

## a) Dane: titanic_train (R-pakiet titanic)

## b) Przygotowanie danych

## c) Redukcja wymiaru na bazie MDS

## d) Wizualizacja danych
