---
title: "Sprawozdanie 4"
author: "Kacper Szmigielski, 282255 i Mateusz Wizner, 277508"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    fig_caption: true
    fig_width: 5
    fig_height: 4
    toc_depth: 3
    number_sections: true
  html_document:
    toc: true
    toc_depth: '3'
    df_print: paged
header-includes:
- \usepackage[OT4]{polski}
- \usepackage[utf8]{inputenc}
- \usepackage{graphicx}
- \usepackage{float}
- \usepackage{xcolor}
- \definecolor{myblue}{HTML}{D0E9F9}
- \definecolor{myyellow}{HTML}{FFFACD}
subtitle: Eksploracja danych
fontsize: 12pt
---

```{r setup, include=FALSE}
#USTAWIENIA DO PROJEKTU 
### echo = FALSE (Nie wypisuje kodu przy egzekucji programu)
### message = FALSE (Nie wyświetla jakiś powiadomień)
### warning = Flase (Nie wyświetla błędów jak się pojawią)
#---------------------------------------------------------
knitr::opts_chunk$set(echo = FALSE,message = FALSE, warning = FALSE )
knitr::opts_chunk$set(fig.pos = "H", out.extra = "", fig.align = "center")
#---------------------------------------------------------
```

```{r biblioteki}
# POTRZEBNE BIBLIOTEKI
#---------------------------------------------------------
library(mlbench)
library(rattle)
library(knitr)
library(MASS)
library(cluster)
library(factoextra)
library(ggplot2)
library(patchwork)
library(dendextend)
library(gtools)
library(mclust)
library(dplyr)
library(e1071)
library(ipred)
library(rpart)
library(rpart.plot)
library(randomForest)
#---------------------------------------------------------
```

```{r kolory}
# Pastelowe kolory (HEX)
#---------------------------------------------------------
pblue    <- "#AEC6CF"
pgreen   <- "#BFD8B8"
ppurple  <- "#CBAACB"
porange  <- "#FFD8B1"
pyellow  <- "#FFFACD"
ppink    <- "#FBB1BD"
pgray    <- "#D3D3D3"  # warm gray
pmint    <- "#C1E1C1"  # cool mint
#---------------------------------------------------------
```

```{r seed}
set.seed(123)
```

\newpage

# Zadanie 1

## a) **Wybór i zapoznanie się z danymi**

```{r wine}
data("wine")
dane <- wine 
```

**Opis** zmiennych w zbiorze danych **Wine**

```{r Opis_danych_wine}
tabela_danych <- data.frame(
  Kolumna = c("V1", "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10", "V11", "V12", "V13"),
  Nazwa_zmiennej = c("Alcohol", "Malic acid", "Ash", "Alcalinity of ash", "Magnesium", 
                      "Total phenols", "Flavanoids", "Nonflavanoid phenols", "Proanthocyanins", 
                      "Color intensity", "Hue", "OD280/OD315 of diluted wines", "Proline"),
  Opis = c("Zawartość alkoholu (%)", "Zawartość kwasu jabłkowego (g/l)", "Zawartość popiołu (g/l)", 
           "Zasadowość popiołu (g/l)", "Zawartość magnezu (mg/l)", "Zawartość fenoli ogółem (g/l)", 
           "Zawartość flawonoidów (g/l)", "Zawartość fenoli nienależących do flawonoidów (g/l)", 
           "Zawartość proantocyjaninów (g/l)", "Intensywność koloru (od 0 do 13)", "Odcień barwy", 
           "Absorbancja przy długości fali 280 nm do 315 nm (rozcieńczone wino)", "Zawartość proliny (mg/l)")
)

kable(tabela_danych, col.names = c("Kolumna", "Nazwa zmiennej", "Opis"))
```


```{r rozklad_klas}
prop <- prop.table(table(dane$Type))
barplot(prop, col = 1:9, ylim = c(0, 0.4), yaxt = "n", main = "Dane Wine - rozkład klas")
axis(2, at = seq(0, 0.4, 0.05), labels = paste0(seq(0, 0.4, 0.05)*100, "%"))
grid()
```



```{r dane_2D}
cechy <- dane[, -1]
wine.pca <- prcomp(cechy, center=TRUE, scale.=TRUE)
#summary(wine.pca)
plot(wine.pca$x[,1:2], col = dane$Type, main = "Dane Wine - PCA", pch = 15, cex = 0.7)
legend("topright", col = 1:3, legend = levels(dane$Type), pch = 15, bg = "azure2")
```
```{r zdolonosc_dyskryminacji}
library(DataExplorer)
plot_boxplot(wine, by="Type")
```


```{r drzewo_kasyfikacyjne}
tree <- rpart(Type~., data=wine) #parametry domyślne
rpart.plot(tree, main="Drzewo klasyfikacyjne - dane Wine", cex=.5)
```
```{r bagging}
# Uwaga:
# wybieramy parametry (minsplit i cp), dla których otrzymujemy drzewa o złożonej strukturze
btree <- bagging(Type~., data=wine, nbagg=25, minsplit=1, cp=0)
btree

# Jak liczba replikacji B (parametr nbagg) wpływa na dokładność modelu?
B.vector <- c(1, 5, 10, 20, 30, 40, 50, 100)
bagging.error.rates <- sapply(B.vector, function(b)  {print(paste0('B=',b)); errorest(Type~., data=wine, model=bagging, nbagg=b, estimator="632plus", est.para=control.errorest(nboot = 20))$error})
plot(B.vector, bagging.error.rates, xlab="B", main="Bagging: error rate vs. B", type="b")
grid()
```

```{r randomowy_las}
# liczba cech
p <-  ncol(wine) - 1

# różne parametry  (ntree - liczba drzew, mtry - liczba wybieranych losowo cech)
rf.1 <- randomForest(Type~., data=wine, ntree=1, mtry=p, importance=TRUE)
rf.1 

rf.2 <- randomForest(Type~., data=wine, ntree=100, mtry=sqrt(p), importance=TRUE)
rf.2

# prognozowane klasy
pred.labels <- predict(rf.2, newdata=wine, type="class")
real.labels <- wine$Type
(confusion.matrix <- table(pred.labels, real.labels)) # dla zbioru uczącego

# prognozowane p-stwa a posteriori
pred.probs <- predict(rf.2, newdata=wine, type="prob")

# macierz pomyłek (confusion matrix)  na bazie OOB (Out-Of-Bag), tzn. obserwacji, 
# które nie były wybierane w danej replikacji
rf.2$confusion

# Wykres błędu klasyfikacji
plot(rf.2)

# Ranking ważności cech
varImpPlot(rf.2,main = "Variable Importance Plot")

```

```{r porównanie_dokładności}
mypredict.rpart <- function(object, newdata)  predict(object, newdata=newdata, type="class")

(error.tree         <- (errorest(Type~., data=wine, model=rpart, predict=mypredict.rpart,
                                 estimator="632plus", est.para=control.errorest(nboot = 20))))
(error.bagging      <- (errorest(Type~., data=wine, model=bagging,
                                 estimator="632plus", est.para=control.errorest(nboot = 20))))
(error.randomForest <- (errorest(Type~., data=wine, model=randomForest,
                                 estimator="632plus", est.para=control.errorest(nboot = 20))))

# Względna redukcja błędu klasyfikacji (w %)
(error.tree$error - error.bagging$error)/error.tree$error*100        # bagging vs. single tree
(error.tree$error - error.randomForest$error)/error.tree$error*100   # random forest vs. single tree

```

## b)

```{r dane2}
dane2 <- na.omit(wine)

n <- nrow(dane2)
learn.ind    <- sample(1:n, 2/3*n)
training.set <- dane2[learn.ind,]
test.set     <- dane2[-learn.ind,]
```


```{r jądra_liniowe}
# UWAGA: na potrzeby ilustracji modele budujemy tylko dla dwóch
# wybranych zmiennych: glucose i age!!!

svm.linear.C0.1 <- svm(Type~Flavanoids+Phenols, data=training.set, kernel="linear", cost=.1)
summary(svm.linear.C0.1)
plot(svm.linear.C0.1, data=training.set, Flavanoids~Phenols, svSymbol=16, grid=100)

svm.linear.C1 <- svm(Type~Flavanoids+Phenols, data=training.set, kernel="linear", cost=1)
summary(svm.linear.C1)
plot(svm.linear.C1, data=training.set, Flavanoids~Phenols, svSymbol=16, grid=100)

svm.linear.C10 <- svm(Type~Flavanoids+Phenols, data=training.set, kernel="linear", cost=10)
summary(svm.linear.C10)
plot(svm.linear.C10, data=dane, Flavanoids~Phenols, svSymbol=16, grid=100)

# konstrukcja prognoz i ocena ich dokładności
real.labels <- test.set$Type
n.test <- length(real.labels)

pred.svm.lin <- predict(svm.linear.C1, newdata=test.set)
(acc.svm.lin   <- sum(diag(table(pred.svm.lin, real.labels)))/n.test)

```


```{r porównanie_funkcji_jadrowych}
svm.poly2  <- svm(Type~Flavanoids+Phenols, data=training.set, kernel="polynomial", degree = 2)
svm.poly4  <- svm(Type~Flavanoids+Phenols, data=training.set, kernel="polynomial", degree = 4)
svm.radial <- svm(Type~Flavanoids+Phenols, data=training.set, kernel="radial")
svm.radial.gamma0.1 <- svm(Type~Flavanoids+Phenols, data=training.set, kernel="radial", gamma=0.1)
svm.radial.gamma1 <- svm(Type~Flavanoids+Phenols, data=training.set, kernel="radial", gamma=1)

# Obszary decyzyjne dla różnych f-cji jądrowych
plot(svm.poly2, data=training.set, Flavanoids~Phenols, svSymbol=16, grid=100)
legend("top",legend="poly degree 2", bg="azure2")
plot(svm.poly4, data=training.set, Flavanoids~Phenols, svSymbol=16, grid=100)
legend("top",legend="poly degree 4", bg="azure2")
plot(svm.radial, data=training.set, Flavanoids~Phenols, svSymbol=16, grid=100)
legend("top",legend="radial", bg="azure2")
plot(svm.radial.gamma0.1, data=training.set, Flavanoids~Phenols, svSymbol=16, grid=100)
legend("top",legend="RBF, gamma=0.1", bg="azure2")
plot(svm.radial.gamma1, data=training.set, Flavanoids~Phenols, svSymbol=16, grid=100)
legend("top",legend="RBF, gamma=1", bg="azure2")

# prognozy i porównanie dokładności
pred.svm.poly2  <- predict(svm.poly2, newdata=test.set)
pred.svm.poly4  <- predict(svm.poly4, newdata=test.set)
pred.svm.radial <- predict(svm.radial, newdata=test.set)

(acc.svm.lin    <- sum(diag(table(pred.svm.lin, real.labels)))/n.test)
(acc.svm.poly2  <- sum(diag(table(pred.svm.poly2, real.labels)))/n.test)
(acc.svm.poly4  <- sum(diag(table(pred.svm.poly4, real.labels)))/n.test)
(acc.svm.radial <- sum(diag(table(pred.svm.radial, real.labels)))/n.test)

```

```{r optymalizacja_parametrów}
# Jądro liniowe (optymalizujemy parametr C)
C.range <- 2^((-4):4)

linear.tune <- tune(svm, train.x=training.set[,c("Flavanoids", "Phenols")],
                    train.y=training.set[,"Type"],
                    kernel="linear", ranges=list(cost=C.range))
linear.tune
plot(linear.tune)

# Jądro gaussowskie (optymalizujemy C i gamma)
gamma.range <- 2^((-8):4)
radial.tune <- tune(svm, train.x=training.set[,c("Flavanoids", "Phenols")],
                    train.y=training.set[,"Type"],
                    kernel="radial",
                    ranges=list(cost=C.range, gamma=gamma.range))

print(radial.tune)
plot(radial.tune, transform.x=log, transform.y=log )
plot(radial.tune, transform.x=log, transform.y=log, color.palette = topo.colors)
plot(radial.tune, type="perspective")


# Dopasowujemy końcowy model dla optymalnych parametrów

C.best <- radial.tune$best.parameters[["cost"]]
gamma.best <- radial.tune$best.parameters[["gamma"]]

svm.radial.tuned <- svm(Type~Flavanoids+Phenols,
                        data=training.set, kernel="radial",
                        cost=C.best, gamma=gamma.best)
summary(svm.radial.tuned)

# Prognozowanie na bazie optymalnego modelu

pred.svm.radial.tuned <- predict(svm.radial.tuned, newdata=test.set)
(acc.svm.radial <- sum(diag(table(pred.svm.radial.tuned, real.labels)))/n.test)
```
# zadanie 2

## a) Wybór i przygotowanie danych

Do analizy skupień wykorzystano zbiór danych **Glass Identification**, zawierający informacje chemiczne na temat różnych rodzajów szkła. Celem analizy jest identyfikacja naturalnych skupień w danych na podstawie składu chemicznego próbek, bez użycia etykiet klas. Zbiór ten jest często wykorzystywany w badaniach klasyfikacyjnych i klasteryzacyjnych jako benchmark

Pełny zbiór zawiera **214 próbek szkła** oraz **9 zmiennych numerycznych**, opisujących zawartość chemicznych pierwiastków (m.in. Na, Mg, Al, Si, Ca). Dodatkowo zawiera zmienną `Type`, określającą rzeczywisty typ szkła (klasa 1–7).

Zmienna `Type` zawiera informację o rodzaju szkła i pełni rolę etykiety klasowej. Ponieważ celem analizy skupień jest znalezienie naturalnych grup bez nadzoru (tzn. bez znajomości klas), zmienna ta została **usunięta przed procesem grupowania**.

Wartości cech w zbiorze różnią się skalą – np. zawartość sodu (Na) czy wapnia (Ca) występuje w innych zakresach niż zawartość żelaza (Fe) czy baru (Ba). Aby zapobiec dominacji zmiennych o większym rozrzucie w macierzy odległości zmienne zostały ustandaryzowane.

```{r wybórDanych}
#WYBÓR DANYCH
#-----------------------------
data("Glass")
dane <- Glass
#-----------------------------

```

```{r usuwanieZmGrupującej}
#USUWANIE KOLUMNY Z ETYKIETAMI
#-----------------------------
Y <- dane[,10]
X <- dane[,-10]
Y <- as.numeric(Y)
#-----------------------------

```

```{r CzyStandaryzować_barplot}

#ODCHYLENIA STANDARDOWE (CZY POTRZEBA STANDARZYACJI)
#-----------------------------
#sds <- sapply(X, sd)
#
#barplt <- barplot(sds,
#        main = "Odchylenia standardowe zmiennych",
#        ylab = "SD",
#        las = 2,         # obraca etykiety osi X
#        col = "steelblue")

#-----------------------------

```

```{r standaryzacja}
#STANDARYZACJA
#------------------
X <-scale(X)
#------------------
```

## b) Grupowanie i wizualizacja

### Grupowanie za pomocą metody PAM

```{r dissimilarity_matrix}
#WYZNACZENIE MACIERZY NIEPODOBIEŃSTW
#------------------------------
X_scaled <- daisy(X)
X_scaled <- as.matrix(X_scaled)
#------------------------------
```

```{r PAM}

#WYZNACZENIE PAM
#------------------------------------------------------
# Model PAM z k = 6
pam_model <- pam(X_scaled, k = 6, metric = "euclidean")

# PCA na standaryzowanych danych
pca <- prcomp(X_scaled, center = TRUE, scale. = TRUE)
pca_df <- as.data.frame(pca$x[, 1:2])

# Dodanie informacji o klastrach i klasach rzeczywistych
pca_df$Klaster <- factor(pam_model$clustering)
pca_df$Klasa <- factor(Y)

# Wykres PCA z kolorami wg klastrów i kształtami wg rzeczywistych klas
ggplot(pca_df, aes(x = PC1, y = PC2, color = Klaster, shape = Klasa)) +
  geom_point(size = 3, alpha = 0.8) +
  labs(title = "PAM na danych Glass: Kolory = Klaster, Kształty = Klasa",
       x = "PC1", y = "PC2") +
  theme_minimal() +
  scale_color_manual(values = RColorBrewer::brewer.pal(6, "Set1")) +  # 6 kolorów
  theme(legend.position = "right")

# Wykres silhouette
#fviz_silhouette(pam_model, palette = RColorBrewer::brewer.pal(7, "Set1")) +
#  labs(title = "Wykres silhouette dla metody PAM na danych Glass")

#------------------------------------------------------

```

Na podstawie analizy wykresu można stwierdzić, że uzyskane skupienia wykazują **umiarkowany poziom separacji** – **najlepiej odseparowany jest klaster nr 6**, natomiast pozostałe częściowo się nakładają. Sugeruje to, że niektóre obserwacje mogą być trudne do jednoznacznego przypisania do jednej grupy.

Pomimo częściowego pokrywania się skupień, wykazują one **dobrą zwartość** – obiekty należące do tego samego klastra są do siebie **stosunkowo podobne**, co świadczy o spójności wewnętrznej grup.

Z drugiej strony, zaobserwowano **niską jednorodność klas pod względem etykiet rzeczywistych** – obiekty należące do różnych klas (oznaczone różnymi kolorami) **mieszają się wewnątrz tych samych skupień**. Szczególnie wyraźne jest to w przypadku **niebieskiej, zielonej i czerwonej**.

```{r Zgodnosci}
# Utwórz tabelę zgodności
tab <- table(pam_model$clustering, Y)

# Dopasuj klastry do klas
dopisanie <- matchClasses(tab, method = "exact")

# Zamień numery klastrów na przypisane klasy
# UWAGA: weź levels klastrów z tabeli, bo mogą być np. 1, 2, 4, 5 (brak 3!)
klastry <- as.integer(rownames(tab))
przypisane_klasy <- dopisanie[as.character(pam_model$clustering)]

# Oblicz dokładność
dokladnosc <- mean(przypisane_klasy == Y) * 100

# Wynik
cat("Dokładność przypisania klastrów do klas:", round(dokladnosc, 2), "%\n")



```

W wyniku analizy zgodności przypisań klastrów do klas rzeczywistych, obliczono tzw. **wskaźnik zgodności (purity)**. Niestety, uzyskana wartość wyniosła jedynie **42.06%**, co należy uznać za **niski poziom dopasowania**.

Taki wynik wskazuje, że **grupowanie metodą PAM** nie odzwierciedla w sposób satysfakcjonujący rzeczywistej struktury klas w danych. **Zastosowanie tego rodzaju podejścia klasteryzacyjnego** do zbioru *Glass* **nie jest w tym przypadku uzasadnione**, ponieważ prowadzi do znacznego nakładania się klas i nie pozwala na ich skuteczne rozróżnienie.

### Podział hierarchiczny

```{r podzial_hierarchiczny}


# AGNES - różne metody łączenia
agnes_avg <- agnes(x = X_scaled, diss = TRUE, method = "average")
agnes_single <- agnes(x = X_scaled, diss = TRUE, method = "single")
agnes_complete <- agnes(x = X_scaled, diss = TRUE, method = "complete")

k <- 6

# Wykresy kołowe dendrogramów z podziałem na 6 klastrów

fviz_dend(agnes_avg, type = "circular", k = k, cex = 0.5, palette = "jco",
          main = "Kołowy dendrogram - AGNES average linkage")

fviz_dend(agnes_single, type = "circular", k = k, cex = 0.5, palette = "jco",
          main = "Kołowy dendrogram - AGNES single linkage")

fviz_dend(agnes_complete, type = "circular", k = k, cex = 0.5, palette = "jco",
          main = "Kołowy dendrogram - AGNES complete linkage")


#------------------------------------------------------------
```

W przypadku metody **single linkage** zaobserwowano wystąpienie tzw. **efektu łańcuchowego** (*chaining effect*). Zjawisko to polega na tym, że kolejne obserwacje są stopniowo dołączane do jednego dużego skupienia na podstawie minimalnych odległości między pojedynczymi punktami, co prowadzi do **tworzenia wydłużonych, sztucznie połączonych struktur**, zamiast wyraźnych, zwartych klastrów.

Przyczyną wystąpienia tego efektu w analizowanych danych jest **duży rozrzut obserwacji** oraz **obecność wartości odstających**. Te same czynniki wpłynęły również negatywnie (leczw o wiele mniejszym stopniu) na wyniki uzyskane za pomocą metody **average linkage**, w której efekt łańcuchowy również jest widoczny, choć w nieco łagodniejszej formie.

W przypadku metody **complete linkage**, zjawisko łańcuchowe **również występuje**, jednak jego **intensywność jest znacząco mniejsza**. Klastery są **bardziej zwarte i lepiej odseparowane**, co przekłada się na **większą równowagę w podziale danych** oraz **lepszą zgodność z rzeczywistym podziałem klas**.

## c) Ocena jakości grupowania. Wybór optymalnej liczby skupień i porównanie metod.

### Wskaźniki wewnętrzne

**W celu dokładniejszego porównania działania poszczególnych algorytmów, ocena została przeprowadzona na oryginalnych (niestandaryzowanych) danych.**

```{r znalezienie najlepszego K}

# Zakres liczby klastrów
K.range <- 2:6

# Metody aglomeracyjne
agnes.methods <- c("average", "complete", "single")

# Ramka na wyniki
results_glass <- data.frame()

for (k in K.range) {
  # PAM
  pam.model <- pam(X_scaled, k)
  sil.pam <- mean(silhouette(pam.model)[, 3])
  results_glass <- rbind(results_glass,
                         data.frame(K = k, Method = "pam", Silhouette = sil.pam))
  
  # AGNES z trzema metodami
  for (method in agnes.methods) {
    agnes.model <- agnes(X_scaled, method = method)
    clust <- cutree(as.hclust(agnes.model), k = k)
    sil.agnes <- mean(silhouette(clust, dist(X_scaled))[, 3])
    method.label <- paste("agnes", method, sep = "_")
    
    results_glass <- rbind(results_glass,
                           data.frame(K = k, Method = method.label, Silhouette = sil.agnes))
  }
}

# Znalezienie najlepszego punktu
best_glass <- results_glass[which.max(results_glass$Silhouette), ]

# Wykres
ggplot(results_glass, aes(x = K, y = Silhouette, color = Method)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  geom_point(data = best_glass, aes(x = K, y = Silhouette), color = "black", size = 3, shape = 4,stroke = 2)  +
  scale_x_continuous(breaks = K.range) +
  labs(
    title = "Średni indeks silhouette: Porównanie metod PAM i AGNES (Glass)",
    x = "Liczba klastrów (K)",
    y = "Średni indeks silhouette"
  ) +
  theme_minimal()

```

**Pomimo że zbiór danych Glass zawiera aż 6 rzeczywistych klas, najwyższa średnia wartość współczynnika silhouette została uzyskana dla podziału na 2 klastry.** Wskazuje to, że dane te posiadają wyraźniejszą, dwugrupową strukturę wewnętrzną, niezależną od etykiet klas przypisanych z góry. **Współczynnik silhouette** mierzy spójność wewnętrzną klastrów oraz ich separację względem siebie, dlatego może preferować mniejszą liczbę skupień, jeśli podział taki lepiej odzwierciedla naturalne różnice między obserwacjami.

### Wskaźniki zewnętrzne 

Funkcja `matchClasses()` (z pakietu **e1071**) zakłada, że liczba klastrów w obu porównywanych partycjach (czyli przewidywanych i rzeczywistych etykietach) **jest taka sama.**

Dlatego pomimo uzyskania najlepszego współczynnika sillhouse dla 2 klastróq, wskaźniki zewnętrzne będziemy porównywać dla 7 klastrów

```{r}
true_labels <- Glass[,10]
true_labels <- as.numeric(true_labels)


true_labels_matched <- as.numeric(as.factor(true_labels))

labels_avg <- cutree(agnes_avg, k = 6)
labels_single <- cutree(agnes_single, k = 6)
labels_complete <- cutree(agnes_complete, k = 6)
labels_pam <- pam_model$clustering

matched_avg <- matchClasses(table(true_labels_matched, labels_avg), method = "exact")
matched_single <- matchClasses(table(true_labels_matched, labels_single), method = "exact")
matched_complete <- matchClasses(table(true_labels_matched, labels_complete), method = "exact")
matched_pam <- matchClasses(table(true_labels_matched, labels_pam), method = "exact")


map_labels <- function(cluster_labels, matched) {
  named <- factor(cluster_labels, levels = seq_along(matched), labels = names(matched))
  matched[as.character(named)]
}


labels_avg_matched <- map_labels(labels_avg, matched_avg)
labels_single_matched <- map_labels(labels_single, matched_single)
labels_complete_matched <- map_labels(labels_complete, matched_complete)
labels_pam_matched <- map_labels(labels_pam, matched_pam)


accuracy_avg <- mean(labels_avg_matched == true_labels_matched)
accuracy_single <- mean(labels_single_matched == true_labels_matched)
accuracy_complete <- mean(labels_complete_matched == true_labels_matched)
accuracy_pam <- mean(labels_pam_matched == true_labels_matched)

results <- data.frame(
  Algorithm = c("AGNES (average)", "AGNES (single)", "AGNES (complete)", "PAM"),
  Accuracy = c(accuracy_avg, accuracy_single, accuracy_complete, accuracy_pam))
```

Na podstawie przeprowadzonych analiz, takich jak **współczynnik silhouette** oraz **dokładność dopasowania**, ustalono, że optymalna liczba skupień wynosi **K=2**. Aby lepiej zrozumieć charakterystykę poszczególnych skupień, przeprowadzono porównanie **średnich wartości cech** oraz analizę ich rozkładów za pomocą **wykresów pudełkowych** dla wybranych zmiennych.

```{r}



# Klasteryzacja aglomeracyjna z metodą complete linkage
agnes_complete <- agnes(X_scaled, method = "complete")

# Wycinamy 2 klastry (zgodnie z Twoim wcześniejszym założeniem K=2)
clusters <- cutree(agnes_complete, k = 2)

# Dodajemy etykiety klastrów do danych
glass_with_clusters <- data.frame(Glass[,-10], Cluster = as.factor(clusters))

# Obliczamy średnie wartości cech w każdym klastrze
cluster_means <- glass_with_clusters %>%
  group_by(Cluster) %>%
  summarise(across(everything(), ~ round(mean(.x, na.rm = TRUE), 2)))


```

```{r średnie wartości cech w skupieniach}
kable(cluster_means, caption = "Średnie wartości cech w skupieniach", label = "tab:comparison_in_clusters" )
```

```{r}


# Definicja funkcji do rysowania boxplotów (Twoja funkcja)
plot_cluster_boxplots <- function(data, cluster_col, features) {
  for (feature in features) {
    p <- ggplot(data, aes(x = .data[[cluster_col]], y = .data[[feature]], fill = .data[[cluster_col]])) +
      geom_boxplot() +
      labs(title = paste("Rozkład", feature, "w skupieniach"),
           x = "Skupienie", y = feature) +
      theme_minimal() +
      theme(plot.title = element_text(hjust = 0.5))
    
    print(p)
  }
}


```

```{r}
# Pobierz nazwę pierwszej cechy (kolumny)
first_feature <- colnames(Glass)[1]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)

```

```{r}
# Pobierz nazwę pierwszej cechy (kolumny)
first_feature <- colnames(Glass)[2]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)

```

```{r}
# Pobierz nazwę pierwszej cechy (kolumny)
first_feature <- colnames(Glass)[3]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)

```

```{r Pobierz nazwę pierwszej cechy (kolumny)}
first_feature <- colnames(Glass)[4]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)


```

```{r}
# Pobierz nazwę pierwszej cechy (kolumny)
first_feature <- colnames(Glass)[5]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)

```

```{r}
# Pobierz nazwę pierwszej cechy (kolumny)
first_feature <- colnames(Glass)[6]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)

```

```{r}
# Pobierz nazwę pierwszej cechy (kolumny)
first_feature <- colnames(Glass)[7]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)

```

```{r}
# Pobierz nazwę pierwszej cechy (kolumny)
first_feature <- colnames(Glass)[8]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)

```

```{r}
# Pobierz nazwę pierwszej cechy (kolumny)
first_feature <- colnames(Glass)[9]

# Rysuj wykres pudełkowy dla tej cechy
plot_cluster_boxplots(glass_with_clusters, cluster_col = "Cluster", features = first_feature)

```
Jak przedstawiono w tabeli (na danych bez standaryzacji, aby zachować ich interpretowalność w realistycznym kontekście), największe różnice średnich wartości cech pomiędzy klastrami zaobserwowano dla zmiennych Ba (bar) oraz Mg (magnez). W szczególności, w klastrze 1 wartości obu tych cech są zauważalnie wyższe, przy czym dla zmiennej Mg występują również istotne wartości odstające.

Co ciekawe, mediana zmiennej Ba w klastrze 2 jest znacznie wyższa niż w klastrze 1, co prowadzi do niemal idealnej separacji między tymi dwiema grupami w wymiarze tej zmiennej. Taka konfiguracja sugeruje, że Ba i Mg stanowią kluczowe czynniki różnicujące struktury klastrowe w badanym zbiorze danych.

Tego rodzaju rozkład jest zgodny z wcześniejszymi założeniami – w kontekście klasyfikacji typu szkła, zawartość baru i magnezu należy do najistotniejszych parametrów różnicujących obserwacje, co znajduje potwierdzenie zarówno w analizie statystycznej, jak i wizualnej.

Warto jednak również przeanalizować, które obserwacje pełnią rolę medoidów (tj. reprezentantów skupień) w przypadku metody PAM (Partitioning Around Medoids) oraz jakie cechy je charakteryzują na tle pozostałych obiektów. Pozwoli to lepiej zrozumieć wewnętrzną strukturę klastrów, a także identyfikować typowe profile obserwacji w ramach poszczególnych grup.



```{r MELTOIDY}

pam_result <- pam(X_scaled, k = 2)  

medoid_indices <- pam_result$id.med

medoids <- Glass[,-10][medoid_indices, ]
kable(medoids, caption = "Analiza meoidów dla metody PAM", label = "tab:medoids")
```

Medoid pierwszego skupienia (rekord nr 36) charakteryzuje się wyraźnie podwyższonymi stężeniami magnezu i potasu, przy jednoczesnym obniżeniu poziomów baru i glinu. Natomiast medoid drugiego skupienia wykazuje odwrotną tendencję – wartości magnezu i potasu są niższe, natomiast stężenia baru i glinu wyższe, przy zachowaniu porównywalnych poziomów pozostałych pierwiastków.

Warto podkreślić, że średnie stężenie żelaza (Fe) w obu medoidach wynosi 0. Wskazuje to, że pierwiastek ten najprawdopodobniej występuje jedynie w śladowych ilościach. Nieliczne wyższe wartości można uznać za obserwacje odstające lub wynikające z przypadkowego zanieczyszczenia próbek.
